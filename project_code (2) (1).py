#######################################################################################################################################################################################
"""                                                             By Nitesh Naresh Narwade
                                             ####################################################################
                                               Email ID: nitesh20329@iiitd.ac.in, darkshadow@11041994@gmail.com
                                         ###############################################################################
                                  

"""
#!/usr/bin/env python
# coding: utf-8

# In[ ]:


# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12uUSVZcpLrLr2xPucnjJpHFyLWyjRtec
"""

# -- coding: utf-8 --
"""Untitled9.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Hcx6sSL-ls0DsIDllSNoYBGanpZC6kXK
"""

#!/usr/bin/env python
# coding: utf-8

# In[11]:


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.datasets import load_digits
from sklearn.neural_network import MLPClassifier
from xgboost import XGBClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation
from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.naive_bayes import BernoulliNB
from sklearn.metrics import log_loss
import pickle

class CrimeClass:

    def __init__(self, trainFile, testFile):
        self.trainFile = trainFile
        self.testFile = testFile
        self._xgb = XGBClassifier(
                            max_depth=7,
                            learning_rate=0.3,
                            n_estimators=30,
                            gamma=0,
                            reg_alpha =0.1,
                            objective = 'multi:softprob',
                            booster='gbtree',
                            silent=True,
                            subsample = .8,
                            colsample_bytree = 0.8,
                            max_delta_step = 1,
                            n_jobs=-1,
                            random_state = 40 
                            )
        self._lr = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1,
                                      class_weight=None, random_state= 42, solver='lbfgs', max_iter=3000, multi_class='multinomial', verbose=1,
                                      warm_start=False, n_jobs=-1, l1_ratio=None)
        #self._lr = LogisticRegression(random_state = 1711,  max_iter = 200, verbose = 1, n_jobs = -1, solver = 'sag', multi_class = 'multinomial')
        self._rf = RandomForestClassifier(n_estimators = 20, random_state = 42)
        self._dt = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=None, min_samples_split=2, 
                                          min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=19, 
                                          random_state= 42, max_leaf_nodes=None, min_impurity_decrease=0.0, 
                                          min_impurity_split=None, class_weight=None, presort='deprecated', 
                                          ccp_alpha=0.0)
        self._nb = GaussianNB(priors=None, var_smoothing=1e-09)
        self._mlp = MLPClassifier(hidden_layer_sizes=100, activation='relu', solver='adam', alpha=0.0001, batch_size='auto', 
                                  learning_rate='constant', learning_rate_init=0.001, power_t=0.5, max_iter=10, shuffle=True, 
                                  random_state=42, tol=0.0001, verbose=True, warm_start=False, momentum=0.9, 
                                  nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, 
                                  beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10, max_fun=15000)
        self.predicted_labels = None
        self.train_labels = None
        self.test_data = None
        self.train_data = None

    def street1_eng(self,address):
        if '/' in address:
                j=address[address.index('/')+1:]
                l=address[:address.index('/')]
                if j>l:
                    return j
                else:
                    return l
        else:
            k=address.split(" ")
            return k[1]

    def street2_eng(self,address):
        if '/' in address:
                j=address[address.index('/')+1:]
                l=address[:address.index('/')]
                if j>l:
                    return l
                else:
                    return j
        else:
            k=address.split(" ")
            return address[address.index('f')+1:]

    def minute_eng(self,minute):
        if minute>30:
            return minute-30
        else:
            return minute

    def is_weekend(self,day):
        if day == 'Friday' or day == 'Saturday' or day == 'Sunday':
            return 1
        else:
            return 0

    def StreetNum_eng(self,address):
        if '/' in address:
            return 'junction'
        else:
            k=address.split(" ")
            return k[0]

    def CountVec(self,data):
        count_vec = TfidfVectorizer(
        max_df = 0.3,
        min_df = 3,
        lowercase = True,
        ngram_range = (1,2),
        analyzer = 'word'
        )
        data_count = count_vec.fit_transform(data.Address)
        indices = pd.DataFrame(count_vec.get_feature_names())

        n_comp = 50
        svd_obj = TruncatedSVD(n_components = n_comp, algorithm = 'randomized')
        svd_obj.fit(data_count)
        data_svd = pd.DataFrame(svd_obj.transform(data_count))
        data_svd.columns = ['svd_char_' + str(i) for i in range(n_comp)]
        data = pd.concat([data, data_svd], axis=1)
        del data_count, data_svd
        return data

    def Preprocess(self,data):
        # data = data[(data['X']< -121)]
        # data = data[(data['Y']<40)]

        scaler=StandardScaler()
        scaler.fit(data[["X","Y"]])
        data[["X","Y"]]=scaler.transform(data[["X","Y"]])

        data["X_1"] = .707* data["Y"] + .707* data["X"]
        data["Y_1"] = .707* data["Y"] - .707* data["X"]
        data["X_2"] = (1.732/2)* data["X"] + (1./2)* data["Y"]
        data["Y_2"] = (1.732/2)* data["Y"] - (1./2)* data["X"]
        data["X_3"] = (1./2)* data["X"] + (1.732/2)* data["Y"]
        data["Y_3"] = (1./2)* data["Y"] - (1.732/2)* data["X"]
        data["radial_Distance"] = np.sqrt( np.power(data["Y"],2) + np.power(data["X"],2) )

        data['Dates'] = pd.to_datetime(data['Dates'])
        data['Year'] = data['Dates'].dt.year
        data['Month'] = data['Dates'].dt.month
        data['Day'] = data['Dates'].dt.day
        data['Hour'] = data['Dates'].dt.hour
        data['Minute'] = data['Dates'].dt.minute
        data=data.drop(['Dates'], axis=1)

        data['Minute'] = data['Minute'].apply(self.minute_eng)

        data['PdDistrict']=data['PdDistrict'].astype('category')
        data['PdDistrict']=data['PdDistrict'].cat.codes

        data["CrossRoad"] = data["Address"].str.contains("/")
        data["CrossRoad"]=data["CrossRoad"].astype('category')
        data["CrossRoad"]=data["CrossRoad"].cat.codes

        data["AV"] = data["Address"].str.contains("AV")
        data["AV"]=data["AV"].astype('category')
        data["AV"]=data["AV"].cat.codes

        data["DayOfWeek"]=data["DayOfWeek"].astype('category')
        data["DayOfWeek"]=data["DayOfWeek"].cat.codes

        data['StreetNo.'] = data['Address'].apply(self.StreetNum_eng)
        data["StreetNo."]=data["StreetNo."].astype('category')
        data["StreetNo."]=data["StreetNo."].cat.codes
        data = data.drop(['Address'], axis=1)

        return data

    def trainingData(self):
      df = pd.read_csv(self.trainFile)
      df = df.drop(['Descript', 'Resolution'], axis=1)
      self.train_labels = df['Category']
      df=df.drop(['Category'], axis=1)
      self.train_data = self.Preprocess(df)

    def testingData(self):
      df = pd.read_csv(self.testFile)
      df = df.drop(['Id'], axis=1)
      df = df.dropna()
      self.test_data = self.Preprocess(df)
    def data(self):
      self.trainingData()
      self.testingData()

    def Model_XGB(self):
        print('\nModel Training...\n')
        label_encoded_y = LabelEncoder().fit_transform(self.train_labels)
        seed = 7
        test_size = 0.15
        X_train, X_test, y_train, y_test = train_test_split(self.train_data, label_encoded_y, test_size=test_size, random_state=seed)
        self._xgb.fit(X_train, y_train,
                eval_set=[(X_test, y_test)],
                eval_metric='mlogloss',early_stopping_rounds=5,
                verbose=True)
        print('\nTraining Ended...\n')
        self.predicted_labels = self._xgb.predict(X_test)
        count = 0
        for i in range (len(y_test)-1):
          if y_test[i] == self.predicted_labels[i]:
            count = count+1       
        print('% in Accuracy:', (count/len(y_test))*100)
        print('\n##########################################################################################################################\n')
        self.predicted_labels= self._dt.predict_proba(self.test_data)
        print(("Log loss: ") + str(log_loss(y_test, self.predicted_labels)))
        print('\n##########################################################################################################################\n')

    def Model_MLP(self):
        print('\nModel Training...\n')
        label_encoded_y = LabelEncoder().fit_transform(self.train_labels)
        seed = 7
        test_size = 0.15
        X_train, X_test, y_train, y_test = train_test_split(self.train_data, label_encoded_y, test_size=test_size, random_state=seed)
      self._mlp.fit(X_train, y_train)
      print('\nTraining Ended...\n')
      self.predicted_labels = self._mlp.predict_proba(X_test)
      print(("Log loss: ") + str(log_loss(y_test , self.predicted_labels)))
      print('\n##########################################################################################################################\n')
      self.predicted_labels= self._mlp.predict(X_test)
      count = 0
      for i in range (len(y_test)-1):
        if y_test[i] == self.predicted_labels[i]:
          count = count+1       
      print('% in Accuracy:', (count/len(y_test))*100)
      print('\n##########################################################################################################################\n')
    

    def Model_LR(self):
        print('\nModel Training...\n')
        label_encoded_y = LabelEncoder().fit_transform(self.train_labels)
        seed = 7
        test_size = 0.15
        X_train, X_test, y_train, y_test = train_test_split(self.train_data, label_encoded_y, test_size=test_size, random_state=seed)
        self._lr.fit(X_train, y_train)
        self.predicted_labels = self._lr.predict(X_test)
        count = 0
        for i in range (len(y_test)-1):
            if y_test[i] == self.predicted_labels[i]:
                count = count+1       
        print('% in Accuracy:', (count/len(y_test))*100)
        print('\n##########################################################################################################################\n')
        self.predicted_labels= self._lr.predict_proba(X_test)
        print(("Log loss: ") + str(log_loss(y_test, self.predicted_labels)))
        print('\n##########################################################################################################################\n')
    
    def Model_RF(self):
        print('\nModel Training...\n')
        label_encoded_y = LabelEncoder().fit_transform(self.train_labels)
        seed = 7
        test_size = 0.15
        X_train, X_test, y_train, y_test = train_test_split(self.train_data, label_encoded_y, test_size=test_size, random_state=seed)
        self._rf.fit(X_train, y_train)
        self.predicted_labels= self._rf.predict(X_test)
        count = 0
        for i in range (len(y_test)-1):
            if y_test[i] == self.predicted_labels[i]:
                count = count+1       
        print('% in Accuracy:', (count/len(y_test))*100)
        print('\n##########################################################################################################################\n')
        self.predicted_labels= self._rf.predict_proba(X_test)
        print(("Log loss: ") + str(log_loss(y_test, self.predicted_labels)))
        print('\n##########################################################################################################################\n')

    def Model_DT(self):
        print('\nModel Training...\n')
        label_encoded_y = LabelEncoder().fit_transform(self.train_labels)
        seed = 7
        test_size = 0.15
        X_train, X_test, y_train, y_test = train_test_split(self.train_data, label_encoded_y, test_size=test_size, random_state=seed)
       
        self._dt.fit(X_train, y_train)
        #tree.plot_tree(self._dt)
        self.predicted_labels= self._dt.predict(X_test)
        count = 0
        for i in range (len(y_test)-1):
            if y_test[i] == self.predicted_labels[i]:
                count = count+1       
        print('% in Accuracy:', (count/len(y_test))*100)
        print('\n##########################################################################################################################\n')
        self.predicted_labels= self._dt.predict_proba(X_test)
        print(("Log loss: ") + str(log_loss(y_test, self.predicted_labels)))
        print('\n##########################################################################################################################\n')

    def Model_NB(self):
        print('\nModel Training...\n')
        label_encoded_y = LabelEncoder().fit_transform(self.train_labels)
        seed = 7
        test_size = 0.15
        X_train, X_test, y_train, y_test = train_test_split(self.train_data, label_encoded_y, test_size=test_size, random_state=seed)
        self._dt.fit(X_train, y_train)
        self.predicted_labels= self._dt.predict(X_test)
        count = 0
        for i in range (len(y_test)-1):
            if y_test[i] == self.predicted_labels[i]:
                count = count+1       
        print('% in Accuracy:', (count/len(y_test))*100)
        print('\n##########################################################################################################################\n')
        self.predicted_labels= self._dt.predict_proba(X_test)
        print(("Log loss: ") + str(log_loss(y_test, self.predicted_labels)))
        print('\n##########################################################################################################################\n')


      

    def MakeSubmission(self):
        col = ['ARSON','ASSAULT', 'BAD CHECKS','BRIBERY','BURGLARY','DISORDERLY CONDUCT',
               'DRIVING UNDER THE INFLUENCE','DRUG/NARCOTIC','DRUNKENNESS','EMBEZZLEMENT',
               'EXTORTION','FAMILY OFFENSES','FORGERY/COUNTERFEITING','FRAUD','GAMBLING',
               'KIDNAPPING','LARCENY/THEFT','LIQUOR LAWS','LOITERING','MISSING PERSON','NON-CRIMINAL',
               'OTHER OFFENSES','PROSTITUTION','RECOVERED VEHICLE','ROBBERY','RUNAWAY','SECONDARY CODES',
               'SEX OFFENSES FORCIBLE','STOLEN PROPERTY','SUICIDE','SUSPICIOUS OCC','TRESPASS','VANDALISM',
               'VEHICLE THEFT','WARRANTS','WEAPON LAWS']
        result = pd.DataFrame(data = self.predicted_labels, columns = col )
        result.insert(0,"Id" , test['Id'])
        result.to_csv('Result.csv', encoding='utf-8', index=False)

    def MakePickle(self):
        filename = 'PickleFile.pkl'
        pkl = open(filename, 'wb')
        pickle.dump(self._xgb, pkl)
        pkl.close()

if __name__ == "__main__":
    train_data_name = "/content/drive/MyDrive/train.csv"
    test_data_name = "/content/drive/MyDrive/test.csv"
    model = CrimeClass(train_data_name,test_data_name)
    model.data()
    def Plot(y):
        if y == 'PA':
            print('Plot the pie chart for the accuracy')
            labels_1 = 'LR', 'MLP', 'DT', 'NB', 'RF', 'XGB'
            Accuracy = [20.1035, 24.9901, 25.3765, 25.413, 27.9891, 32.8681]
            colors_1 = ['gold', 'yellowgreen', 'lightcoral', 'lightskyblue', 'orange', 'red']
            explode_1 = (0, 0, 0, 0, 0, 0.1)
            plt.pie(Accuracy, explode=explode_1, labels=labels_1, colors=colors_1, autopct='%1.1f%%', shadow=True, startangle=140, )
            plt.axis('equal')
            plt.show()
        if y == 'LL':
            print('Plot the pie chart for the log_loss:')
            labels_2 = 'LR', 'MLP', 'DT', 'NB', 'RF', 'XGB'  
            log_loss = [2.6525, 2.4767, 24.9036, 24.8821, 16.9014, 2.2265]
            colors_2 = ['gold', 'yellowgreen', 'lightcoral', 'lightskyblue', 'orange', 'red']
            explode_2 = (0, 0, 0, 0, 0, 0.1)
            plt.pie(log_loss, explode=explode_2, labels=labels_2, colors=colors_2, autopct='%1.1f%%', shadow=True, startangle=140, )
            plt.axis('equal')
            plt.show()
    def Run(x):
        if x =='DT':
            print('\n##########################################################################################################################\n')
            model.Model_DT()
        if x =='XGB':
            print('\n##########################################################################################################################\n')
            model.Model_XGB()
        if x =='LR':
            print('\n##########################################################################################################################\n')
            model.Model_LR()
        if x =='RF':
            print('\n##########################################################################################################################\n')
            model.Model_RF()
        if x=='NB':
            print('\n##########################################################################################################################\n')
            model.Model_NB()
        if x =='MLP':
            print('\n##########################################################################################################################\n')
            model.Model_MLP()
            return print('                                   THANK YOU FOR YOUR TIME                                                                                        ')
print('\n##########################################################################################################################\n')
print('\n                                 HELLO WELL-COME TO THE CRIME CLASSIFICATION OF SAN-FRANCISO                              \n')
print('\n                                              BY. NITESH Naresh NARWADE                                        \n')      
print('Please Enter:')      
print('1] DT  to  Run Decesion Tree')
print('2] XGB to  Run XG Boost')
print('3] LR  to  Run Logistic Regression')
print('4] RF  to  Run the Random Forest')
print('5] NB  to  Run the Naive Bayes')
print('6] MLP to  Run the Multiple Layer Perceptron')
print('\n###########################################################################################################################\n')                   
x = str(input('Enter the short form of Model from above to run the respective Model:'))
Run(x)

print('Please Enter:')
print('1] PA to plot accuarcy pie chart')
print('2] LL to plot accuracy pie chart')
print('\n###########################################################################################################################\n')
y = str(input('Enter the short form of plot from above to run the respective plot'))
print('\n###########################################################################################################################\n')
Plot(y)

